# üëÅÔ∏è VisionTools
> **Advanced Computer Vision Pipeline for Traffic Analytics & Object Tracking**

![Python](https://img.shields.io/badge/Python-3.9%2B-blue?style=for-the-badge&logo=python)
![YOLO](https://img.shields.io/badge/AI-YOLOv11-orange?style=for-the-badge)
![OpenCV](https://img.shields.io/badge/Vision-OpenCV-green?style=for-the-badge&logo=opencv)
![PyTorch](https://img.shields.io/badge/Deep%20Learning-PyTorch-red?style=for-the-badge&logo=pytorch)

<p align="center">
  <img src="https://via.placeholder.com/800x400.png?text=Place+Demo+GIF+Here" alt="VisionTools Demo" width="100%">
</p>

## üìã Overview

**VisionTools** is a modular, production-ready computer vision system designed to extract meaningful insights from video feeds. Built with a focus on Clean Architecture and extensibility, it leverages state-of-the-art Deep Learning (YOLOv11) combined with classical computer vision algorithms to perform robust object tracking, speed estimation, and behavioral analysis.

This project demonstrates advanced engineering capabilities in **MLOps**, **Software Architecture**, and **Real-time Processing**.

---

## üöÄ Key Features

### üéØ Precision Object Tracking
- **Hybrid Tracking Engine**: Combines **Kalman Filters** for motion prediction with **Color Histograms** for appearance re-identification.
- **Occlusion Handling**: Robust logic to maintain object identity through temporary obstructions.
- **Lifecycle Management**: Sophisticated state machine for track initialization, confirmation, and termination.

### ‚ö° Intelligence & Analytics
- **Speed Estimation**: Implements homography transformation (perspective mapping) to convert pixel displacement into real-world velocity (km/h).
- **Multi-Class Detection**: Capable of distinguishing between cars, trucks, buses, motorcycles, and pedestrians.
- **Zone-Based Analysis**: Configurable regions of interest (ROI) for specific monitoring tasks.

### üõ†Ô∏è Engineering Excellence
- **Modular Architecture**: Components (Input, Output, Processing) are decoupled via Adapters, making the system highly testable and maintainable.
- **Configurable Pipeline**: Entire behavior driven by a centralized `config.json` file.
- **Dual Output**: Generates both visual overlays (Annotated Video) and structured data (CSV) for downstream analytics.

---

## üèóÔ∏è System Architecture

```mermaid
graph TD
    A[Video Input] --> B(Frame Preprocessing)
    B --> C{YOLOv11 Inference}
    C --> D[Object Detection]
    D --> E[TrackZone Adapter]
    
    subgraph Tracking Engine
    E --> F[Kalman Filter Prediction]
    F --> G[Data Association]
    G --> H[Track Lifecycle Manager]
    end
    
    subgraph Analytics
    H --> I[Speed Calculator]
    I --> J[Perspective Calibration]
    end
    
    H --> K[Output Buffer]
    K --> L[Annotated Video]
    K --> M[Data CSV]
```

---

## üíª Getting Started

### Prerequisites
- Python 3.9+
- CUDA-compatible GPU (Recommended for real-time performance)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/visiontools.git
   cd visiontools
   ```

2. **Set up environment**
   ```bash
   # Create virtual environment
   python -m venv .venv
   source .venv/bin/activate  # Linux/Mac
   # .venv\Scripts\activate   # Windows
   
   # Install dependencies
   pip install -r requirements.txt
   ```

3. **Run the Analyzer**
   ```bash
   python main.py
   ```

---

## ‚öôÔ∏è Configuration

The system is fully customizable via `config.json`:

- **`GEOMETRY_CONFIG`**: Define monitoring zones and calibration points.
- **`MODEL_CONFIG`**: Swap YOLO models and adjust confidence thresholds.
- **`TRACKING_CONFIG`**: Tune Kalman parameters for specific scenarios.

---

